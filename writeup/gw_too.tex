\section{Gravitational Wave Target of Opportunity Follow-up}

\subsection{Introduction}

Gravitational wave detectors have begun detecting mergers of massive objects such as neutron stars and black holes. The signature of such events in gravitational waves provides information not only on their masses, but also an estimate of the distance to the merger. This estimate is independent of any optical photometry, or even detection, and as such can be used to estimate the local value of $H_0$ using a distance measurement independent of the traditional distance ladder. To complete the calculation of $H_0$, however, a redshift must also be measured, which in turn requires that the source be identified in optical images and a redshift measured. Identification of such optical counterparts is challenging: the ability of gravitational wave detectors measure the celestial coordinates of these mergers is limited. Provided the merger itself generates a distinctive electromagnetic signature, a survey that can quickly detect this signature over the whole GW localization area and distinguish it from other variable sources can provide the necessary coordinates for spectroscopic follow-up, either of the host galaxy or the event itself. Mergers between neutron stars (kilonovae) are examples of such events. One such event has been discovered so far. (TODO: REFERENCE) However, the precision on the measurement of $H_0$ from and individual event is limited, and the uncertainty encompasses the discrepant measurements of $H_0$ from other methods: a large sample of such events is required to fulfill the potential of such events for cosmology.

LSST is well suited to detect kilonovae: the systematic and automated operations of LSST will allow rapid and reliable response to triggers, the sensitivity and large field of view will allow the localization area provided by GW detectors to be surveyed quickly, and other LSST surveys will be ideal for providing templates and rejects catalogs.

An astrophysical rate of $1500$ events $\mbox{Gpc}^{-3}$ $\mbox{yr}^{-1}$, a sensitivity volume of $0.03 \mbox{Gpc}^3$ \todo{explain that this will increase as GW detector upgrades occur}, and a detector uptime fraction of $0.8$ results in $\sim 36$ events per year. Of these, 25\% will be north of $\delta=30\degree$, and a further 10\% will be too close to the sun, so only 23 events can be followed up per year -- about one event every 2 weeks. The tiling scheme for WFD exposures has a density of about $1/7.8\square\degree$. In the HLV O3 configuration, the median localization will be $\sim 23 \square\degree$, so observing passes on the best localized kilanova triggers will require $\sim 4$ pointings. The distribution is skewed, so the mean will be larger than the median. Few GW detected kilanova will have a localization worse than $60 \square \degree$, and so most such kilanova triggers can be completed using 8 visits per filter per pass.

% Fig 3 from Chen & Holz 2016 for CDF of localization area

\subsection{Follow-up strategy}

The proposed follow-up strategy closely resembles that developed, extensively studied \todo{references}, and executed \todo{references} on DECam for GW followup\footnote{Simply scaling by telescope aperture, a 90 second exposure on DECam (the standard DES exposure time, and the exposure time used for GW follow-up) corresponds to 36 seconds of exposure time in LSST. An LSST WFD visit (pair of exposures totaling 30 seconds) will have roughly the same depth as a DECam GW followup exposure. LSST FWD pointings have a density of $\sim 1/7.8\square\degree$, while DES pointings have a density of $\sim 1/3.2\square\degree$, so LSST will be able to cover the same area of sky with 40\% of the visits required by DECam.  DECam also has a much longer readout time, such that exposures can only be taken at a rate of one every 120 seconds. So, use of LSST for GW followup (and many other projects) will be very similar to DECam, except that LSST can cover the same area of sky to the same depth in roughly 1/8th the time. In other words, the effective etendue of LSST is about 8 times that of DECam, and individual standard DES visits have roughly the same depth as individual standard LSST WFD visits.}. To identify optical sources corresponding to GW signals from kilonovae, we must detect the object in LSST images, identify it as variable, and distinguish it from other variable sources. Most objects can be rejected as kilonavae candidates either because they show no variation relative to previous exposures, or because they have been previously identified as other types of variable objects.

Distinguishing kilonovae from other transient objects is a greater challenge. For each GW trigger, we will use one of two strategies to distinguish kilonovae from supernovae or other transient objects.

When possible, we will attempt to detect the rising light curve. Kilonovae brighten for ~12 hours after the GW detection, while other transient object fall in brightness for most of their lifetime. So, if we can accomplish it within 12 hours of the GW detection, we will cover the GW localization region in two passes separated by one hour. When following this strategy, exposures are only required on one filter, but both passes must be made in the same filter. A poorly localized ($60 \square\degree$) detection can be followed up using this technique in 16 visits, or about 10 minutes of LSST observing time. We estimate the detection rate (the fraction of the time we correctly detect the source) for followups using this strategy to be INPROGRESS, and the false positive rate to be INPROGRESS.

If it is not possible to detect the rising light curve (for example because the region is not accessible during the required time window), we will distinguish kilonovae from supernovae and other transient variable sources using the color evolution. For this, we also need two passes, but the two passes should be separated by one day, and images in two filters must be collected in each pass. A poorly localized ($60 \square\degree$) detection can be followed up using this technique in 32 visits, or about 20 minutes of LSST observing time. We estimate the false negative rate (the fraction of the time we fail to detect the source) for followups using this strategy to be \todo{}, and the false positive rate to be \todo{}.

% Maybe we should have a table with time for best localized, time for all, true detection rate, false detection rate

\subsection{Impact on other LSST programs}

If LSST uses these strategies to follow up GW detections with a mean localization of $60\square\degree$ at a rate of $\sim 37$ per year, then roughly $0.2\%$ of WFD exposures are affected. Because GW follow-up can use the same visit parameters as the WFD survey, these exposures are not removed from the WFD where the localization area overlaps the WFD footprint: the exposures are simply taken at a different time. Where the localization region falls outside of the FWD footprint, the time spent following up GW is entirely lost to the WFD. In FWD survey strategies that utilize a larger footprint, such as the LynneSim footprint introduced at the Flatiron cadence hackathon, GW followup will be less disruptive. 

GW followup may also affect the observing cadences of other programs. However, the exact timing of the follow-up passes will often be somewhat flexible on the hour timescale: when following the "color-evolution" strategy, the exact timing of the passes on each night is not critical, provided the localization region as accessible.

% - Many exposures will be reusable as WFD exposures
%  + Some will be too far north
%  + TODO calculate the fraction of exposures in the FWD footprint.
%  + May not match the WFD cadence desired for other programs
%  + the color-evolution based followup is more flexible in exact time of followup
% - The rate of 36/year results in a small fraction of time affected
% If WFD is wider area, it makes GW less disruptive, and helps GW in other ways (templates)

\subsection{Metrics}

The definitive metric for GW follow-up is the final uncertainty on the derived value of $H_0$, which varies statistically as $\sqrt{n_{\mbox{kn}}}$. The number of kilonovae detected is a function of the time dedicated to triggered follow-up, but not linearly: if follow-up is constrained in time, we will follow up GW signals with the best constrained localization regions, so that the mean time used per kilonova increases as we can follow up less and less constrained signals.

% TODO: Plot of number of kilanovae detected vs. time spent on triggered followup. This should serve as the desired plot in the one page writeup for the SSTF on Thursday.

% H0 vs. num detected plot

%  - Number (area) of GW candidates followed up
%    + corresponds to time used

\subsection{The mini survey parameters}

Total exposure time 2.5 nights per year in the most conservative case (37 events per year, 60 square degrees per event in average, 20 minutes per event). 
Results of runs with the simulator: 3/4 of a night per year.

We should note that the rate of events could be up to 10 times higher, if upcoming upgrades to LIGO during the lifetime of LSST are included. In that scenario, we would need about 7.5 nights per year, under these very conservative assumptions.

We estimate that the gwtoo mini-survey will start with a request of about ~1 night per year in the beginning of the survey, and gradually increase as the sensitivity of LIGO increases, achieving  up to 5 nights per year by the end of the survey. That is about 1.3\% of the total LSST survey time to be invested in this science case. 
