\RequirePackage{docswitch}
% \flag is set by the user, through the makefile:
%    make note
%    make apj
% etc.
\setjournal{\flag}

\documentclass[\docopts]{\docclass}

% You could also define the document class directly
%\documentclass[]{emulateapj}

% Custom commands from LSST DESC, see texmf/styles/lsstdesc_macros.sty
\usepackage{lsstdesc_macros}

\usepackage{graphicx}
\graphicspath{{./}{./figures/}}
\bibliographystyle{apj}

% Add your own macros here:

%% \watermark{draft}
\usepackage{draftwatermark}

% ======================================================================

\begin{document}
% \nocite{*}

\title{Seeing values for LSST strategy simulations}

\maketitlepre

\begin{abstract}

The \texttt{opsim4} operations simulation program for the LSST
astronomical survey uses a database of seeing values covering the
range of times to be simulated. I describe the creation of such a
database using Dual Image Motion Monitor (DIMM) data collected at
Cerro Pachon from 2014-03-17 to 2019-10-07. In times during which the
data overlap, I compare the distribution of DIMM seeing values to the
seeing measured in DECam images, taken at a site ~10 km
away. Instrumental problems in the DIMM may indicate unreliable
measuremens, cuts on image quality (as indicated by the measured
Strehl ratio) were explored. The DIMM has significant gaps, so I model
the data (with and without cuts on Strehl ratio) and generate
artificial data in the gaps according to the model. The model consists
of a sinusoidal variation with a period of one year, an autoregressive
(AR1) model for variations in mean seeing from one night to the next,
and another AR1 model for variations on a 5 minute timescale. I create
four databases according to this procedure, two based on DIMM data
starting 2006-01-01 (with and without a Strehl ratio cut), and two
starting 2009-01-01. I then run \texttt{opsim} simulations using each,
and an otherwise identical simulation using the default seeing
database, and explore the differences.
\end{abstract}

% Keywords are ignored in the LSST DESC Note style:
\dockeys{}

\maketitlepost

% ----------------------------------------------------------------------
% {% raw %}

\section{Introduction}
\label{sec:intro}

The Large Synoptic Survey Telescope (LSST) is a telescope currently
under construction on Cerro Pachon, in Chile. It will spend 10 years
performing an astronomical survey, taking repeated images across a
large fraction of the sky visible from Cerro Pachon. It will take
images of any given area of the sky multiple times, spread across many
nights, so that transient objects may be detected and characterized.

Turbulence in the Earth's atmosphere causes short time-scale variations
in the index of refraction of the air. These variations place limits
on the sharpness of astronomical images taken by telescopes on the
surface of the Earth; this limit is called the ``seeing'', typically
measured as the angular full width at half maximum (FWHM) of the image
of a point source, the ``point spread function'' (PSF), that would be
taken by an ideal instrument. The seeing is a property of the weather,
and as such is correlated with the location, time of year, and
transient weather patterns. \textcite{2009PASP..121..922E}, for example,
measure a significant variation in seeing with time of year at Cerro
Tololo, a site $\sim10 \mbox{ km}$ from Cerro Pachon.

The \texttt{opsim} operations simulationor generates a database of
exposures plausible for an execution of the survey. Each exposure in
the database includes several parameters, including the time the
exposure was taken, the depth of the image (the brightness of the
faintest objects detected at a given signal to noise ratio), and the
delivered PSF FWHM. The LSST project and science groups use these
databases of simulated exposures to evaluate the data quality that
would result from different operations strategies. Such evaluations
can then be used both to select among candidate observing strategies,
and set expectations for the scientific usefulness of the LSST data
set.

To calculate the depth and PSF FWHM of each simulated exposure, the
simulator must have a value for the atmospheric seeing at the time the
image was taken. It takes these values from a simple database table, which
provides atmospheric seeing values at a set of times.

The seeing data is not only used to calculate the data quality values
for each exposure in the final database; it may also affect the
scheduling of the exposures themselves. Some science programs are more
sensitive to the seeing than others, and the scheduler can
use this data in its choice of which exposure to take at a given
time. For example, a less urgent exposure needed for one program may
be taken in preference to a more urgent exposure needed for another,
if the seeing is too poor for the data to be useful for the more
urgent exposure, but adequate for the less urgent one.

TTherefore, the details of the seeing database used by \texttt{opsim}
can affect the results in several ways:

\begin{itemize}
  \item The global quality of the survey is strongly affected by the
    contents of the seeing database. If the average seeing in the
    seeing database is worse, the average delivered PSF FWHM in the
    images that comprise the survey will be worse, as will the depth
    of the survey.
  \item The accessible area in the sky varies with a period of one
    year, which corresponds to the yearly seasonal variation in the
    seeing. For example, the same area on the sky can be imaged in
    January every year, and a different area every July. If the seeing
    is better in January than in July of every year, then the data
    quality in the area of sky accessible in January will be better
    than that accessible in July.
  \item The autocorrelation of seeing over time will also affect the
    data quality of light curves of transient objects: if the seeing
    is weakly correlated over timescale similar to the duration of a
    transient event, then the quality of different points on the light
    curve will be uncorrelated. On the other hand, if the
    autocorrelation of the seeing over time is strong on the timescale
    of the event, then it is more likely for the seeing to be either
    good or poor over the whole duration of the event.
  \item The autocorrelation of the seeing over time on timescales
    similar to the time between one exposure and the next will affect
    the ability of the scheduler to react appropriately to changes in
    seeing. 
    
\end{itemize}

The seeing conditions on Cerro Pachon have been monitored since 2004
using a Dual Image Motion Monitor, or DIMM. A DIMM measures the
position of a star through two neighboring paths through the
atmosphere, typically separated by $\sim10 \mbox{ cm}$. The difference
in positions between these two paths indicates the variability in
measured position due to turbulence on that spatial scale. The Fried
parameter, the diameter of a circular aperture over which the RMS
wavefront error induced by atmospheric turbulence is one radian, can
be derived directly from DIMM measurements [\cite{1965JOSA...55.1427F,
    1987PASP...99.1360M, 2002PASP..114.1156T}].

The archive of DIMM data for Cerro Pachon records seeing values
derived for $0.5 \micron$ light using a Kolmogorov turbulence model,
which may be pessimistic. \cite{2002PASP..114.1156T} provides a
formula for approximating a more realistic von K\'arm\'an model,
provided one can estimate the outer scale of the turbulence.

The default seeing database used by \texttt{opsim4} version 081217 was
artificially generated from a model derived from a more limited set of
data from the Cerro Pachon DIMM, and repeats with a period of two
years.

Observing strategy simulation for the Dark Energy Survey (DES)
[\cite{2016MNRAS.460.1270D}] had a similar
requirement. \texttt{obstac} [\cite{2014ASPC..485...77N}], the DES operations
scheduler and simulator, used seeing data sets generated using a model
derived from data from the DIMMs on Cerro
Tololo [\cite{2012ASPC..461..201N}]. The model used by \texttt{obstac} included
both a seasonal component and a short timescale autoregressive model,
producing seeing values on 5 minute intervals.

%% Plots in this note were generated using \texttt{jupyter} notebooks
%% that can be found in github:
%% \url{https://github.com/LSSTDESC/obs_strat/tree/master/doc/seeing}. The
%% \texttt{simsee} application itself can be found in the same product:
%% \url{https://github.com/LSSTDESC/obs_strat/tree/master/code/simsee}. Data
%% files not included in the \texttt{github} product can be found in the
%% \texttt{/global/project/projectdirs/lsst/survey\_sims/input/seeing}
%% directory on \texttt{cori.nersc.gov}.

% ----------------------------------------------------------------------

\section{Overview}
\label{sec:overview}

The following procedure was followed in generating new seeing
databases and exploring their effects on \texttt{opsim4} simulations:

\begin{itemize}

  \item Obtain the Cerro Pachon DIMM data, and explore it
    interactively, as provided. See section~\ref{sec:dimm}.
  \item Validate the DIMM data through comparison with seeing
    estimated using DECam imaging. Examine the agreement between these
    data sets as a function of the Strehl ratio recorded for the DIMM,
    and filter the DIMM data accordingly.
  \item For each DIMM measurement, calculate the Fried parameter,
    $r_{0}$, and seeing based on the von K\'arm\'an model using the
    correction given in \cite{2002PASP..114.1156T} and an outer scale
    of $\mathcal{L}_{0} = 30$ meters, based on the measurement
    reported in \cite{2000ApOpt..39.5415Z}.
  \item Resample the DIMM data to obtain a data set sampled on 5
    minute intervals.
  \item Interactively explore long time-scale variability, and fit
    a sine with a period of 1 year to the nightly mean value of
    $\log(r_{0})$.
  \item Interactively explore the nightly residuals of $\log(r_{0})$
    (after subtraction of the seasonal model), and fit the residuals
    using autoregressive (AR1) models on each uninterrupted sequence
    of consecutive nights with DIMM data. Derive a global AR1 model
    for nightly residuals using a weighted average of the parameters
    as derived from each sequence of nights.
  \item Interactively explore the short time-scale residuals of
    $\log(r_{0})$ (after subtraction of the nightly mean values), and fit the
    residuals using a second autoregressive (AR1) model on each
    consecutive sequence of values in the resampled data. (Gaps
    in DIMM data during the night result in breaks between sequences
    in the resampled data.) Derive a global AR1 model for short
    time-scale residuals using a weighted average of the parameters as
    derived from each sequence.
  \item Generate four seeing databases, using four different subsets
    of the Cerro Pachon DIMM data, corresponding to two different
    start dates, each cut on not cut on Strehl ratio. Use the derived
    models to fill in gaps in the DIMM data with values randomly
    generated according to the derived seasonal, nightly, and
    short-timescale AR models.
  \item Run five \texttt{opsim4} simulations: one using the default seeing
    database, and one for each of the newly generates seeing
    databases, and compare the results.
\end{itemize}

\section{Cerro Pachon DIMM data}
\label{sec:dimm}

\cite{ebustos} kindly provided an the Cerro Pachon DIMM data in the
form of two text tables, each with a timestamp and an
airmass-corrected seeing value for a wavelength of 0.5\micron,
derived using a Kolmogorov seeing model.

Figure~\ref{fig:monthly-dimm-vs-year} shows the variation in
reported FWHM seeing values with time. The regular extremes of good
and poor seeing, shortly after the start and midpoint of each year,
match well with anecdotal experience, and indicate a significant
seasonal component. There are also noticeable long-term trends, but on
a timescale comparable to or greater than the range of the data, so no
attempt is made to model these longer term trends here. This feature
is also evident in the autocorrelation function of the nightly means,

\begin{figure*}
  \includegraphics[width=\columnwidth]{monthly_dimm_vs_year.png}
  \caption{
    Horizontal black lines show the median DIMM seeing in each
    month. Dark gray bars extend from the first though the third
    quartiles for each month, and light bars from the 5\% to 95\%
    quantiles.
    The think red line shows the median FWHM seeing as derived from
    DECam imaging (after subtraction in quadrature of a 0.45''
    instrumental contribution, and correction to zenith and
    500nm). Thin red lines show the first and third quartiles, and
    thin orange lines the 5\% and 95\% quantiles.
    }
  \label{fig:monthly-dimm-vs-year}
\end{figure*}


Figure~\ref{fig:dimm-vs-decam} compares the seeing quantiles for
different months of DIMM and DECam data. The correspondence is worst
when the seeing is very poor (and so is unlikely to be useful in any
case), and in very good seeing, during which DECam seems to hit a hard
floor (about where the PSF becomes undersampled).

\begin{figure*}
  \includegraphics[width=\columnwidth]{dimm_vs_decam.png}
  \caption{
    Each point represents a quantile in the FWHM distribution of a
    month, as measured by DECam (horizontal axis) and the DIMM
    (vertical). The shape and size indicated which quantile, and the
    color the median DIMM Strehl ratio in that month.
    }
  \label{fig:dimm-vs-decam}
\end{figure*}

\section{DIMM data quality and Strehl ratio}

A DIMM can give unreliable results if it is out of focus or poorly
aligned. One diagnostic is the Strehl ratio of the DIMM data (see Wang
et al 2006). However, the Strehl ratio may also be low due to
atmospheric seeing itself. Figure~\ref{fig:strehl-boxplots} shows both
of these effects: the upper panel shows that DIMM and DECam seeing are
well matched except when the Strehl ratio falls below 0.25, where the
DIMM shows significantly wider PSF FWHMs than the corresponding DECam
data. On the other hand, the lower panel shows that the DECam seeing
is genuinely worse when the DIMM Strehl ratio is less than 0.25, such
that filtering the DIMM data based on Strehl ratio will bias the data
in the other direction. Fortunately, the fraction of DIMM data with a
Strehl ratio below 0.25 is low (see figure~\ref{fig:strehl-hist}), so
it may not make much difference. Seeing simulations based on cut and
uncut DIMM data will be used to indicated the range.

\begin{figure*}
  \includegraphics[width=\columnwidth]{strehl_boxplots.png}
  \caption{
    The upper panel shows the distribution of the fractional
    difference between DECam and DIMM seeing in hourly bins, split by
    the median DIMM Strehl ratio for these bins. The lower panel shows
    a similar distribution of the simple DECam seeing, similarly
    binned. Blue bars show the median, and red boxes the second and
    third quaritiles. Whiskers indicate the 5\% and 95\% quantiles.
    }
  \label{fig:strehl-boxplots}
\end{figure*}

\begin{figure*}
  \includegraphics[width=\columnwidth]{strehl_hist.png}
  \caption{
    A histogram of the median Strehl ratio in each hour of DIMM observing.
  }
  \label{fig:strehl-hist}
\end{figure*}

\section{The legacy seeing database}

As of October 2019, \texttt{opsim} uses a seeing database artificially
generated using statistics derived from Pachon DIMM data taken between
2004-05-06 and 2006-01-20, after a cuts on data with low Strehl ratios
in the left star image. Figure~\ref{fig:claver-strehl-cut} indicates
that the cut value was 0.3 for data taken before 2005-06-17
(MJD=53538), and 0.5 for data taken after.

\begin{figure*}
  \includegraphics[width=\columnwidth]{claver_strehl_cut.png}
  \caption{
    2D histograms of the left DIMM Strehl ratio and date in the subset
    of DIMM data used to generate the legacy \texttt{opsim} seeing data, before
    (left) and after (right) appliction of cuts on Strehl ratios.
  }
  \label{fig:claver-strehl-cut}
\end{figure*}


\section{The Fried parameter}

The Fried parameter, $r_0$, was then calculated for each reported
value by inverting equation~5 of \cite{2002PASP..114.1156T}.
Figure~\ref{fig:r0-dist} shows the
distribution of measured values for the $r_0$, in meters (left) and
$\log(r_0)$ (right), together with best fit normal
distributions. Neither distribution is precisely normal, but $\log(
r_0)$ is noticeably closer.

\begin{figure*}
  \includegraphics[width=\columnwidth]{r0_dist.png}
  \caption{The upper row shows the distribution of the Fried parameter, $r_0$ in meters
    (left), and $\log(r_0)$ (right), together with best fit normal
    distributions. The lower row shows the corresponding
    probability plots.}
  \label{fig:r0-dist}
\end{figure*}

%% The
%% nightly autocorrelation of the nightly mean values of $r_0$
%% (figure~\ref{fig:raw-dimm-autocorr}) also shows the seasonal effect.
%% \begin{figure*}
%%   \includegraphics[width=\columnwidth]{raw_dimm_autocorr.png}
%%   \caption{The autocorrelation function of the mean values of $\log(
%%     r_0$. The horizontal solid and dashed bars mark the 95\% and 99\%
%%     confidence intervals for uncorrelated data.}
%%   \label{fig:raw-dimm-autotorr}
%% \end{figure*}


Figure~\ref{fig:random-nights-dimm} shows the time series of DIMM
measurements for three nights, chosen randomly from among nights with
good DIMM coverage. 

\begin{figure*}
  \includegraphics[width=\columnwidth]{random_nights_dimm.png}
  \caption{The time series of DIMM
measurements for three nights, chosen randomly from among nights with
good DIMM coverage. }
  \label{fig:random-nights-dimm}
\end{figure*}

\subsection{Seasonal fit}
\label{sec:seasonal}

The first stage in creating a model for the seeing data was to fit a
sine curve (plus a constant) with a period of one year to
$\log(r_0)$ (equation~\ref{eq:seasonal-sine}).

\begin{equation} \label{eq:seasonal-sine}
\log(r_0) = a + c \times \cos\left( (\mbox{day} - d) \times \frac{2\pi}{365.24217} \right)
\end{equation}

\begin{table}
\begin{center}
  \begin{tabular}{ l l l } \hline
      & uncut & cut \\ \hline
  $a$ & -0.9163 & -0.9119\\
  $c$ & 0.04 & 0.04 \\
  $d$ & 24.3 &  23.2 \\ \hline
  Nightly $\mbox{L1}$ & 0.23 & 0.22 \\
  Nightly $e$ & 0.082 & 0.088\\ \hline
  5 minute $\mbox{L1}$ & 0.68 & 0.73\\
  5 minute $e$ & 0.052 & 0.052\\ \hline
\end{tabular}
\caption{Parameters for the least squares fit of Pachon DIMM data to
  equation~\ref{eq:seasonal-sine}, the nightly autoregressive model,
  and the short time-scale autoregressive model.}\label{tab:fit-params}
\end{center}
\end{table}

A sine was chosen as the simplest periodic
function. Table~\ref{tab:fit-params} shows the best fit
values. Figure~\ref{fig:monthly-boxplot} shows the distribution of the
mean $\log(r_0)$ values for each month, before and after subtraction
of the seasonal model. Before subtraction of the model, months near
the middle of the year have obviously worse seeing, an effect not
visible after subtraction. Figure~\ref{fig:seasonal-sub-autocorr}
shows the autocorrelation functions of the monthly mean $\log(r_0)$
values. The seasonal effect is again prominent before subtraction of
the seasonal fit. Longer timescale variations are still apparent after
subtraction of the seasonal model, but there is no obvious periodic
structure.

\begin{figure*}
  \includegraphics[width=\columnwidth]{monthly_boxplot.png}
  \caption{The top plot shows the distributions of mean monthly values
    for each month. The blue bar shows the median mean value for that
    month, the box the 1st and 3rd quartiles, and the whiskers the
    5\% and 95\% quantiles. The bottom plot shows the distributions after
    subtraction of the seasonal fit to $\log(r_0)$.}
  \label{fig:monthly-boxplot}
\end{figure*}

\begin{figure*}
  \includegraphics[width=\columnwidth]{seasonal_sub_autocorr.png}
  \caption{The upper and lower plots show the autocorrelation function
  of the mean $\log(r_0)$ by month, before and after subtraction of
  the seasonal model, respectively. The solid and dashed gray lines show
  the 95\% and 99\% ranges for uncorrelated data.}
  \label{fig:seasonal-sub-autocorr}
\end{figure*}

\subsection{Nightly variation in seeing}
\label{sec:nightly-variation}

After subtraction of the seasonal variation in $\log(r_0)$,
significant night to night correlation remains. The modeled here as a
first-order autoregressive process [\cite{cryer_time_2008}], also
referred to as an AR(1) process or a damped random walk
[\cite{2009ApJ...698..895K}], described in
equation~\ref{eq:ar1}. Here, $y_t$ is the difference between the mean
$\log(r_0)$ on that night and the seasonal model for
$\log(r_0)$. $\mbox{L1}$ is the regressive term, the model parameter
that represents the correlation between one night and the next, and
$e_t$ is the ``innovation'', analogous to the step sizes in a random
walk.

\begin{equation} \label{eq:ar1}
y_t = \mbox{L1} \times y_{t-1} + e_t
\end{equation}

There are many nights in the Cerro Pachon DIMM data set with no data.
The tool used to fit the AR1 model, from the python
\texttt{statsmodels} module [\cite{seabold2010statsmodels}], does not
handle missing data. To fit the AR1 model, I divided the full data set
into sequences of consecutive nights without missing data, performed
separate fits on each sequence, and accepted the mean values provided
by the models, weighted according to the reported uncertainty in each
model fit. Table~\ref{tab:fit-params} lists the resultant fit
parameters.

The distribution values in a sequence of points generated by an AR1
process is a normal distribution with a variance given by
equation~\ref{eq:ar1var}[\cite{cryer_time_2008} eqn. 4.3.3].

\begin{equation} \label{eq:ar1var}
\sigma_y^2 = \frac{\sigma_e^2}{1-\mbox{L1}^2}
\end{equation}

Figure~\ref{fig:night-ar1-dist} shows the expected distribution given
the fit model parameters over-plotted over the actual histogram of
$\log(r_0)$ - seasonal fit $\log(r_0)$. The distribution expected from
the AR1 fit is sharper than the measured one, and does not capture the
tail on the low-$\log(r_0)$ side of the distribution. The later is a
fundamental limitation of the model. The sharper distribution likely
arises from the fit of a collection of sub-sequences of nights, rather
than a full, uninterrupted data set:
figure~\ref{fig:monthly-dimm-vs-year} clearly shows variations on
timescales of months to years, too long to be captured by the
sub-sequences of nights to which the AR1 model was fit.

\begin{figure*}
  \includegraphics[width=\columnwidth]{night_ar1_dist.png}
  \caption{The histogram of differences between nightly mean
    $\log(r_0)$ and the seasonal fit, over-plotted by the result that
    would be expected by the fit AR1 model.}
  \label{fig:night-ar1-dist}
\end{figure*}

\subsection{Short timescale variation in seeing}
\label{sec:short-variation}

In addition to varying on a nightly basis, seeing varies on much
shorter timescales. The short-timescale variations are modeled using
an AR1 model as well. The raw DIMM data is sampled irregularly,
slightly more frequently than once every 5 minutes. I therefore
resample the points onto exact 5 minute intervals, and divide it in into
sub-sequences of consecutive uninterrupted exposures, similar to the
procedure for nightly data. Table~\ref{tab:fit-params} lists the
resultant fit parameters.

\subsection{Correction from Kolmogorov to von K\'arm\'an turbulence}
\label{sec:vkcorr}

The raw data provided by the Cerro Pachon DIMM archive provides seeing
data calculated using a Kolmogorov model for the turbulence in the
atmosphere. This data was used to work backward to the Fried
parameter, $r_0$, which was then modeled. To obtain simulation seeing
values from the $r_0$ model, I use the approximation given in
equation~\ref{eq:ktovk}, provided by \cite{2002PASP..114.1156T}.

\begin{equation} \label{eq:ktovk}
\left( \frac{\mbox{FWHM}_{vK}}{\mbox{FWHM}_{K}} \right)^2
\approx 1 - 2.183 \left( \frac{r_0}{\mathcal{L}_0} \right)^{0.356}
\end{equation}

I use a value of $\mathcal{L}_0 = 30$ meters, based on the
value of $28.4^{+25.0}_{-13.3}$ meters reported by
\cite{2000ApOpt..39.5415Z} for Cerro Pachon. This corresponds to a 22\%
improvement in seeing when converting from a Kolmogorov to a
von~K\'arm\'an turbulence model and a typical value of $r_0$, but the
range given is from 18\% to 30\%. Furthermore, the value reported was
measured data from only a few nights of data, and is likely to be
strongly dependent on weather.

\subsection{Seeing data generation}
\label{sec:data-generation}

Much of the data to be used by an \texttt{opsim} simulation can be copied
directly from the historical DIMM data, after conversion from a
Kolmogorov to a von~K\'arm\'an turbulence model and application of an
offset in time by an integer number of years. The gaps can then be
filled in using the model.

For sequences of nights with no data, mean values for each night are
calculated using the seasonal model (equation~\ref{eq:seasonal-sine})
and the nightly AR1 model (equation~\ref{eq:ar1}) with the last night
of data with DIMM data and randomly generated values of $e_t$. For
sequences of short time-scale (5 minute interval) points, artificial
data is generated similarly, using the nightly mean, the last good
DIMM data point, and random values of $e_t$.

Two different seeing databases were generated: one using a 13 year
offset (such that the 2022-01-01T00:00:00Z data point in the data set
is copied from the 2009-01-01T00:00:00Z DIMM data), and one using a 16
year offset, such that we take full advantage of all available DIMM
data. Note that there is overlap between the DIMM data used by these
two database, so the results are not uncorrelated.

\subsection{\texttt{opsim} simulations}
\label{sec:simulations}

Three separate simulations were run using \texttt{opsim}, specificaly
\texttt{sims\_featureScheduler} revision \texttt{b9f8585} and
\texttt{sims\_featureScheduler\_runs\_1.3} revision
\texttt{2aba222}. Each simulation was run for a full 10-year LSST
survey, with the default configuration except for the seeing database.

\begin{description}
  \item[\texttt{baseline\_v1.3\_10yrs}] a 10-year simulation using the defaults
    seeing database, used as a reference.
  \item[\texttt{ss58777y13\_v1.3\_10yrs}] a simulation using the
    \texttt{simsee\_pachon\_58777\_13.db} seeing database, which uses
    uncut DIMM data from 2009-01-01 to 2019-10-07 to simulate
    2022-01-01 to 2033-10-07 and the seeing model derived from uncut
    DIMM data to generate simulated data for gaps. This simulation is otherwise identical
    to \texttt{baseline\_v1.3\_10yr}.
  \item[\texttt{ss58777y16\_v1.3\_10yrs}] a simulation using the
    \texttt{simsee\_pachon\_58777\_16.db} seeing database, which uses
    uncut DIMM data from 2006-01-01 to 2019-10-07 to simulate
    2022-01-01 to 2036-10-07 and the seeing model derived from uncut
    DIMM data to generate simulated data for gaps. This simulation is otherwise identical
    to \texttt{baseline\_v1.3\_10yr}.
  \item[\texttt{ss58779y13\_v1.3\_10yrs}] a simulation using the
    \texttt{simsee\_pachon\_58779\_13.db} seeing database, which uses
    cut DIMM data from 2009-01-01 to 2019-10-07 to simulate 2022-01-01
    to 2033-10-07 and the seeing model derived from cut DIMM data to
    generate simulated data for gaps. This simulation is otherwise
    identical to \texttt{baseline\_v1.3\_10yr}.
  \item[\texttt{ss58779y16\_v1.3\_10yrs}] a simulation using the
    \texttt{simsee\_pachon\_58779\_16.db} seeing database, which uses
    cut DIMM data from 2006-01-01 to 2019-10-07 to simulate 2022-01-01
    to 2036-10-07 and the seeing model derived from cut DIMM data to
    generate simulated data for gaps. This simulation is otherwise
    identical to \texttt{baseline\_v1.3\_10yr}.
\end{description}

% ----------------------------------------------------------------------

\section{Results}
\label{sec:results}

Figure~\ref{fig:simseecomp} shows the seeing as a function of time, as
recorded in the databases produced by each of the five runs of
\texttt{opsim}. The two year periodicity of the seeing that results
from the default two year input database is apparent in the leftmost
plot in the figure. Yearly periodicity, expected from the seasonal
variation in the DIMM data and model, is apparent in the plots from
the other two runs. 


\begin{figure*}
\begin{center}
  \minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{seeing_baseline_v1_3_10yrs.png}
\endminipage\hfill
\end{center}
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{seeing_ss58777y13_v1_3_10yrs.png}
\endminipage\hfill
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{seeing_ss58777y16_v1_3_10yrs.png}
\endminipage\hfill
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{seeing_ss58779y13_v1_3_10yrs.png}
\endminipage\hfill
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{seeing_ss58779y16_v1_3_10yrs.png}
\endminipage\hfill
  \caption{Each plot shows the variation in seeing with time
    produced by a different run of \texttt{opsim}. The top plot
    shows the seeing for the default seeing database, and the
    remaining plots show the seeing for each of the seeing databases
    produced by \texttt{simsee}.} 
  \label{fig:simseecomp}
\end{figure*}

Figure~\ref{fig:simseemaps} shows maps of the mean seeing in the LSST
wide-fast-deep (WFD) survey from each simulation. Degradation is
apparent near the northern and southern edges of all three
simulations. This is expected, because these areas are never at low
airmass from Cerro Pachon. At a give range in declination, there is
also variation with R.A. This variation is much more pronounced in the
revised seeing databases than in the baseline: in the baseline, the
best 6 hours of R.A. have a mean seeing 6\% better than the worst 6
hours, while for the revised seeing simulations the difference is
about 12\% (or 14\% if not cut on Strehl ratio is applied). 

\begin{figure*}
\begin{center}
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{seeing_map_baseline_v1_3_10yrs.png}
\endminipage\hfill
\end{center}
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{seeing_map_ss58777y13_v1_3_10yrs.png}
\endminipage\hfill
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{seeing_map_ss58777y16_v1_3_10yrs.png}
\endminipage\hfill
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{seeing_map_ss58779y13_v1_3_10yrs.png}
\endminipage\hfill
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{seeing_map_ss58779y16_v1_3_10yrs.png}
\endminipage\hfill
  \caption{Each plot shows the map of mean seeing
    produced by a different run of \texttt{opsim}. The top plot
    shows the seeing for the default seeing database, and the
    remaining plots show the seeing for each of the seeing databases
    produced by \texttt{simsee}.} 
  \label{fig:simseemaps}
\end{figure*}

The variation in seeing corresponds to a variation in depth, shown in
figure~\ref{fig:simdepthmaps} and the right-hand plot in
figure~\ref{fig:seelimra}, so there is a
similar difference in the amplitude of variation for limiting
magnitude: in the baseline, there is a difference of about 0.14
magnitudes between the mean limiting magnitudes of the best and worst
6 hours of R.A., while in the revised seeing simulations the difference is
about 0.20 magnitudes.

\begin{figure*}
\begin{center}
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{depth_map_baseline_v1_3_10yrs.png}
\endminipage\hfill
\end{center}
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{depth_map_ss58777y13_v1_3_10yrs.png}
\endminipage\hfill
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{depth_map_ss58777y16_v1_3_10yrs.png}
\endminipage\hfill
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{depth_map_ss58779y13_v1_3_10yrs.png}
\endminipage\hfill
\minipage{0.5\textwidth}
  \includegraphics[width=\columnwidth]{depth_map_ss58779y16_v1_3_10yrs.png}
\endminipage\hfill
  \caption{Each plot shows the map of mean depth
    produced by a different run of \texttt{opsim}. The top plot
    shows the depth for the default seeing database, and the
    remaining plots show the depth for each of the seeing databases
    produced by \texttt{simsee}.} 
  \label{fig:simdepthmaps}
\end{figure*}

\begin{figure*}
  \includegraphics[width=\columnwidth]{seeing_depth_by_ra.png}
  \caption{The seeing and depth as a function of RA for different runs
  of \texttt{opsim4}.} 
  \label{fig:seelimra}
\end{figure*}



% ----------------------------------------------------------------------

\section{Discussion}
\label{sec:discussion}

The use of a longer baseline of real seeing data (and a more elaborate
model for times when such data is not available) in operations
simulations demonstrates a significant, large angular scale variation
in seeing (and therefore depth) using the current strategy, as well as
a mean shift to wider PSF (and therefore shallower limiting
magnitude). The impact of this variation on science results needs to
be carefully evaluated and, if warranted by the science, adjustments
to the strategy made to mitigate these effects.

Such mitigation strategies will necessarily come at a cost. The
current strategy is designed to observe fields when they are near
transit. Such a strategy optimizes the quality of data taken at any
given time: a field observed near transit at a given declination will
have a better FWHM than another at the same declination, but further
from transit. Observing fields near transit, however, necessarily maps
time of observation directly to sidereal time, which is correlated
with time of year, and therefore the seasonal variation in seeing.

This correlation can be reduced by observing fields when they are
further from transit, depending on seeing conditions. Such a strategy
can be designed to even out the extremes in the variation. However (if
the strategy maintains the global distribution in declination) these
exposures will be at higher airmasses than those that would have been
taken at transit, which will degrade the overall mean image quality.

A compromise will need to be made. The effect on image quality is not
linear with zenith distance (or time from transit), but is shallow
very close to transit, and degrades more rapidly as the angle
increases: a mild deviation from the transiting strategy may only have
a mild effect on the mean image quality.

\section{Future work}
\label{sec:future}

Although an improvement over the default seeing database, the revised
seeing databases presented here leave significant room for
improvement. Some refinements that should be explored include:

\begin{itemize}

\item Creating a better model of the poor seeing tail in the
  distribution of seeing values, either as an additional component or
  by transforming the DIMM's $\log(r_0)$ distribution.

\item Interactive exploration and informal experience suggest that the
  seeing has a systematic variation with the time of night, in
  particular that the seeing is slightly worse shortly after
  sunset. This needs to be studied further, and perhaps modeled as
  well.

\item Rigorous evaluation of higher-order ARMA models using a formal
  criteria (either Akaike's Information Criterion (AIC) or a Bayesian
  Information Criterion (BIC))[\cite{cryer_time_2008} pp. 130-132],
  rather than the AR1 model used here. The AR1 model was selected due
  to its simplicity and apparent effectiveness after informal
  exploration; additional terms and/or a moving average component may
  be warranted.

\item Modeling the short term, nightly, seasonal, and long term
  components as a single seasonal ARMA model, following the formalism
  described in \cite{cryer_time_2008} chapter 10. Rather than fit each
  element separately (as has been done here), this approach
  incorporates long-term effects by including additional terms in the
  autoregressive equation.
  
\item Modeling using a continuous ARMA model (CARMA)
  [\cite{brockwell_introduction_1996} pp. 344-348] rather than the
  discrete ARMA model used here. Such models are significantly more
  complex and lack the well developed software tools, but naturally
  handle the irregularly sampled nature of the DIMM data.
  
\end{itemize}

Long term (multi-year) trends in seeing are apparent in the DIMM data,
however, and improvement from any of the above seems likely to be
minor compared to the uncertainty due to these trends. Finally, it
seems unlikely that any of these imporvements will have a major effect
on survey strategy metrics anyway.

In addition to modeling the seeing, improved modeling of the effect of
clouds in survey data quality should also be studied.

% ----------------------------------------------------------------------

\section{Conclusion}
\label{sec:conclusion}

The full archive of data from the Cerro Tololo DIMM shows strong
seasonal variations, and larger mean values for the seeing, than are
present in the default input database used by the LSST \texttt{opsim}
operations simulator. Inclusion of an updated seeing database is
therefore important for using \texttt{opsim} to evaluate both the
overall survey quality and also large scale variation in seeing and
depth across the survey footprint.

% ----------------------------------------------------------------------

\subsection*{Acknowledgments}

I am grateful to Edison Bustos and other staff of the National Optical
Astronomical Observatory (NOAO) for supplying the data used in this
study, and discussions with Chuck Claver that led to an understanding
of the origin of the baseline data set.

This manuscript has been authored by Fermi Research Alliance, LLC
under Contract No. DE-AC02-07CH11359 with the U.S. Department of
Energy, Office of Science, Office of High Energy Physics.

%%% Here is where you should add your specific acknowledgments, remembering that some standard thanks will be added via the \code{desc-tex/ack/*.tex} and \code{contributions.tex} files.

%This paper has undergone internal review in the LSST Dark Energy Science Collaboration. % REQUIRED if true

\input{contributions} % Standard papers only: author contribution statements. For examples, see http://blogs.nature.com/nautilus/2007/11/post_12.html

% This work used TBD kindly provided by Not-A-DESC Member and benefitted from comments by Another Non-DESC person.

% Standard papers only: A.B.C. acknowledges support from grant 1234 from ...

\input{desc-tex/ack/standard} % also available: key standard_short

% This work used some telescope which is operated/funded by some agency or consortium or foundation ...

% We acknowledge the use of An-External-Tool-like-NED-or-ADS.

%{\it Facilities:} \facility{LSST}

% Include both collaboration papers and external citations:
\bibliography{main,lsstdesc}

\end{document}

% ======================================================================
